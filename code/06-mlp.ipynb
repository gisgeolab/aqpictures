{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2c439d-2737-462c-9de4-e4950a6ef09d",
   "metadata": {},
   "source": [
    "# PM2.5 Prediction using MLP Neural Network\n",
    "\n",
    "This notebook demonstrates the prediction of PM2.5 concentrations using a Multi-Layer Perceptron (MLP) neural network. The model uses meteorological variables, atmospheric energy parameters, and webcam-derived RGB features to estimate particulate matter concentrations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72427ed1-6911-4809-b802-636e0c3e54e1",
   "metadata": {},
   "source": [
    "Import necessary libraries for data processing, visualization, and deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366eaf5-7455-49d7-b820-64a0072a8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01731b48-521f-4423-872d-33783192f6cf",
   "metadata": {},
   "source": [
    "## Reproducibility Settings\n",
    "\n",
    "Set random seeds for NumPy and TensorFlow to ensure reproducible results across different runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619afba8-5f33-4c7e-b6be-ec47ec85b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd800cf-6a3c-4c57-8c4a-4a6331d49225",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the input dataset containing meteorological variables, RGB features from webcam images, and PM2.5 measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148542f7-f083-429a-9f54-99ab26c41295",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Model Input/ML_DL_input.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddb039-60e5-4e94-ad7a-5f8097bcb500",
   "metadata": {},
   "source": [
    "## Datetime Processing\n",
    "\n",
    "Create a datetime column by combining Date and Hour fields for temporal analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3da856-ef00-43e9-8ab0-991a547f0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Hour'].astype(str), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd670bc-ee80-4472-8e01-42128fbd656b",
   "metadata": {},
   "source": [
    "## Feature Engineering: Atmospheric Energy Parameters\n",
    "\n",
    "Calculate atmospheric energy features at two pressure levels (500 hPa and 850 hPa):\n",
    "- **Density (ρ)**: Air density calculated using the ideal gas law\n",
    "- **Kinetic Energy (KE)**: Energy from wind velocity components (U, V)\n",
    "- **Geopotential Energy (GE)**: Gravitational potential energy\n",
    "\n",
    "These features capture atmospheric dynamics relevant to pollutant dispersion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3277e-d535-496c-9486-7b09d59f5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_500=df['T_500']\n",
    "T_850=df['T_850']\n",
    "Ro_500=T_500.map(lambda x: 50000*29/(8314*(x)))\n",
    "Ro_850=T_850.map(lambda x: 85000*29/(8314*(x)))\n",
    "\n",
    "U_500=df['U_500']\n",
    "V_500=df['V_500']\n",
    "U_850=df['U_850']\n",
    "V_850=df['V_850']\n",
    "\n",
    "KE_500=0.5*Ro_500*(U_500**2+V_500**2)\n",
    "KE_850=0.5*Ro_850*(U_850**2+V_850**2)\n",
    "\n",
    "GP_500=df['GP_500']\n",
    "GP_850=df['GP_850']\n",
    "GE_500=Ro_500*GP_500\n",
    "GE_850=Ro_850*GP_850\n",
    "\n",
    "df['GE_500']=GE_500\n",
    "df['KE_500']=KE_500\n",
    "df['GE_850']=GE_850\n",
    "df['KE_850']=KE_850"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79385251-7db3-4de0-b692-2f59e944914c",
   "metadata": {},
   "source": [
    "## Feature Engineering: RGB Color Ratios\n",
    "\n",
    "Calculate color ratios from webcam imagery (sky and ground regions):\n",
    "- **R/G, R/B, B/R ratios**: Color channel relationships\n",
    "- **RGB sum**: Total brightness indicator\n",
    "\n",
    "These features capture atmospheric turbidity and visibility conditions that correlate with PM2.5 concentrations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecabd8-df05-4cd6-8a1b-3c18cc2d3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_G_Sky= df['R_S_M']/df['G_S_M']\n",
    "R_B_Sky = df['R_S_M']/df['B_S_M']\n",
    "RGB_Sky = df['R_S_M']+df['G_S_M']+df['B_S_M']\n",
    "G_R_Sky= df['G_S_M']/df['R_S_M']\n",
    "B_R_Sky= df['B_S_M']/df['R_S_M']\n",
    "\n",
    "R_G_Ground= df['R_G_M']/df['G_G_M']\n",
    "R_B_Ground = df['R_G_M']/df['B_G_M']\n",
    "RGB_Ground = df['R_G_M']+df['G_G_M']+df['B_G_M']\n",
    "\n",
    "df['R_G_Sky']=R_G_Sky\n",
    "df['R_B_Sky']=R_B_Sky\n",
    "df['B_R_Sky']=B_R_Sky\n",
    "df['RGB_Sky']=RGB_Sky\n",
    "df['R_G_Ground']=R_G_Ground\n",
    "df['R_B_Ground']=R_B_Ground\n",
    "df['RGB_Ground']=RGB_Ground\n",
    "\n",
    "PM25 = df['PM25']\n",
    "\n",
    "GE_500=df['GE_500']\n",
    "BLH=df['BLH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cb332-93d6-4e1b-8ffa-f2a84fc86581",
   "metadata": {},
   "source": [
    "## Feature Engineering: Temporal Cyclical Encoding\n",
    "\n",
    "Encode hour and month as cyclical features using sine and cosine transformations. This preserves the circular nature of time (e.g., hour 23 is close to hour 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333b136-c0ed-43a2-ac5f-b33d5df3f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hr']=df['Datetime'].dt.hour\n",
    "df['mnth']=df['Datetime'].dt.month\n",
    "print(df['hr'].unique(),df['mnth'].unique())\n",
    "\n",
    "df['hr_sin'] = np.sin(df.hr*(2.*np.pi/24))\n",
    "df['hr_cos'] = np.cos(df.hr*(2.*np.pi/24))\n",
    "df['mnth_sin'] = np.sin((df.mnth-1)*(2.*np.pi/12))\n",
    "df['mnth_cos'] = np.cos((df.mnth-1)*(2.*np.pi/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d63305-a57b-4517-9eae-72e879a3173b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Prepare the dataset for modeling:\n",
    "1. Define target variable (PM2.5) and columns to drop\n",
    "2. Remove non-numeric and temporal columns\n",
    "3. Handle missing values\n",
    "4. Separate features (X) and target (y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960976e-59c9-49f2-b91e-60d073c634a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['PM25']\n",
    "drop_cols = ['Datetime', 'Date', 'Hour', 'hr', 'mnth']\n",
    "\n",
    "df2 = df.drop(columns=[c for c in drop_cols if c in df.columns]).copy()\n",
    "df2 = df2.select_dtypes(include=[np.number]).copy()\n",
    "df2 = df2.dropna().reset_index(drop=True)\n",
    "\n",
    "# Feature and target selection\n",
    "x_cols = [c for c in df2.columns if c not in y_cols]\n",
    "print(f\"Features: {len(x_cols)}\")\n",
    "print(f\"Target: {y_cols}\")\n",
    "print(f\"Total samples: {len(df2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f1c50-8fa7-43d5-9348-408c9293d1c1",
   "metadata": {},
   "source": [
    "## Chronological Train-Test Split\n",
    "\n",
    "Split data chronologically (not randomly) to simulate real-world forecasting:\n",
    "- Training: First 80% of temporal data\n",
    "- Testing: Last 20% of temporal data\n",
    "\n",
    "This approach prevents data leakage and provides realistic performance estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c88b2b-3f60-4b65-88c6-a1867f8c859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[x_cols].to_numpy()\n",
    "y = df2[y_cols].to_numpy()\n",
    "\n",
    "test_frac = 0.2\n",
    "n = len(df2)\n",
    "split_idx = int((1 - test_frac) * n)\n",
    "\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "print(f\"Total rows: {n}\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7885e72-0999-4601-ab1d-b6d6fb22abd7",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "\n",
    "Apply Min-Max scaling to normalize features and target to [0, 1] range:\n",
    "- Fit scalers on **training data only** to prevent data leakage\n",
    "- Transform both train and test sets using training statistics\n",
    "- Keep scalers for inverse transformation of predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4ae48-92da-4642-93f9-e2abd9a5406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = MinMaxScaler(feature_range=(0, 1))\n",
    "sy = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train_s = sx.fit_transform(X_train)\n",
    "X_test_s = sx.transform(X_test)\n",
    "\n",
    "y_train_s = sy.fit_transform(y_train)\n",
    "y_test_s = sy.transform(y_test)\n",
    "\n",
    "print(\"Scaling complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc15d8d-b88f-4fd6-9698-dbfd9516f7db",
   "metadata": {},
   "source": [
    "## MLP Model Architecture\n",
    "\n",
    "Build a Multi-Layer Perceptron (MLP) for regression:\n",
    "- **Input layer**: Number of features\n",
    "- **Hidden layers**: 3 dense layers (32, 32, 16 neurons) with ReLU activation\n",
    "- **Output layer**: Single neuron (PM2.5 prediction) with linear activation\n",
    "- **Optimizer**: Adam with learning rate = 0.001\n",
    "- **Loss function**: Mean Squared Error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e083b-56f6-4c3f-9891-f31e2b829192",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_train_s.shape[1]   \n",
    "n_output = y_train_s.shape[1]  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(n_input,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff3442-d1a4-4890-bec1-ee73ba7bd5cc",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train the MLP with early stopping:\n",
    "- **Epochs**: Maximum 300\n",
    "- **Batch size**: 256\n",
    "- **Early stopping**: Monitor validation loss with patience=20\n",
    "- **Validation**: Use test set for monitoring (chronological split ensures no leakage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c1985-19d5-44ad-b0d2-2ec4c70b4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_s, y_train_s,\n",
    "    epochs=300,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_test_s, y_test_s),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bed01a-5aff-459e-96c8-e38dfbcaf005",
   "metadata": {},
   "source": [
    "## Training History Visualization\n",
    "\n",
    "Plot training and validation loss curves to assess model convergence and potential overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7676d7-2698-494b-9409-15b10c1cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5), dpi=150)\n",
    "plt.plot(history.history['loss'], label='Train MSE (scaled)')\n",
    "plt.plot(history.history['val_loss'], label='Test MSE (scaled)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MLP Training History')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1ddb0-69f8-49b3-af97-69b41f3a7e88",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate model performance on test set using original units (µg/m³):\n",
    "- **RMSE**: Root Mean Squared Error\n",
    "- **MAE**: Mean Absolute Error\n",
    "- **R²**: Coefficient of determination\n",
    "\n",
    "Predictions are inverse-transformed from normalized space back to original scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c6723-0ba8-44d0-b8be-fda2a8c06076",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_s = model.predict(X_test_s, verbose=0)\n",
    "yhat_test = sy.inverse_transform(yhat_test_s)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, yhat_test))\n",
    "mae = mean_absolute_error(y_test, yhat_test)\n",
    "r2 = r2_score(y_test, yhat_test)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.3f} µg/m³\")\n",
    "print(f\"Test MAE:  {mae:.3f} µg/m³\")\n",
    "print(f\"Test R²:   {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec100e41-50b5-403b-b667-4e87b8c42d47",
   "metadata": {},
   "source": [
    "## Prediction Visualization\n",
    "\n",
    "Scatter plot comparing observed vs. predicted PM2.5 values. Points along the diagonal indicate perfect predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb02fa-d7dc-4557-ba6b-aafb5242d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6), dpi=150)\n",
    "plt.scatter(y_test, yhat_test, s=8, alpha=0.5, edgecolors='none')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel(\"Observed PM2.5 (µg/m³)\")\n",
    "plt.ylabel(\"Predicted PM2.5 (µg/m³)\")\n",
    "plt.title(\"Observed vs Predicted PM2.5 (Test Set)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('comparison_mlp.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
